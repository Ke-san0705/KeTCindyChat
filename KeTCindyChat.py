import os
import json
import numpy as np
import faiss
from dotenv import load_dotenv
from openai import OpenAI
from tqdm import tqdm

# --- ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ---
load_dotenv()
client = OpenAI()

# --- è¨­å®š ---
EMBED_MODEL = "text-embedding-3-small"
DATA_DIRS = [
    "./KeTCindy_Learningfile/jsonl/Learning_jsonl",
    "./KeTCindy_Learningfile/jsonl/Np_jsonl",
    "./KeTCindy_Learningfile/jsonl/Samplecode_jsonl"
]
TOP_K = 3
REJECT_PATTERNS = ["import ", "def ", "matplotlib", "plt.", "print(", "Python"]

# --- JSONLãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
entries = []
for data_dir in DATA_DIRS:
    for fname in os.listdir(data_dir):
        if fname.endswith(".jsonl"):
            full_path = os.path.join(data_dir, fname)
            with open(full_path, "r", encoding="utf-8") as f:
                for line in f:
                    obj = json.loads(line)
                    entries.append(obj)

# --- Embeddingç”Ÿæˆ ---
print("ğŸ”„ ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­...")
# åŸ‹ã‚è¾¼ã¿ç”¨ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡ºã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
texts = [entry.get("content") or entry.get("completion") for entry in entries]
texts = [t for t in texts if t and t.strip()]  # â† ã“ã‚Œã‚’è¿½åŠ ï¼ˆç©ºãƒ»Noneã‚’é™¤å¤–ï¼‰

embeddings = []

for i in tqdm(range(0, len(texts), 100)):
    batch = texts[i:i + 100]
    res = client.embeddings.create(model=EMBED_MODEL, input=batch)
    batch_embeddings = [d.embedding for d in res.data]
    embeddings.extend(batch_embeddings)

embedding_matrix = np.array(embeddings).astype("float32")

# --- FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ ---
index = faiss.IndexFlatL2(len(embedding_matrix[0]))
index.add(embedding_matrix)

# --- å¿œç­”ç”Ÿæˆé–¢æ•° ---
def search_and_respond(query):
    query_vec = client.embeddings.create(
        model=EMBED_MODEL,
        input=[query]
    ).data[0].embedding

    D, I = index.search(np.array([query_vec]).astype("float32"), TOP_K)
    results = [entries[i] for i in I[0]]
    context = "\n\n".join(
        [f"ã€{r.get('title') or r.get('prompt')}ã€‘\n{r.get('content') or r.get('completion')}" for r in results]
    )

    # --- ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª­ã¿è¾¼ã¿ ---
    with open("system_prompt.txt", "r", encoding="utf-8") as f:
        system_prompt = f.read()

    for attempt in range(2):
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"{context}\n\nè³ªå•ï¼š{query}"}
            ],
            temperature=0.2
        )
        content = response.choices[0].message.content
        if not any(pat in content for pat in REJECT_PATTERNS):
            return content
    return "âš ï¸ KeTCindyå½¢å¼ã§ã®å‡ºåŠ›ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚è³ªå•ã‚’ã‚‚ã†å°‘ã—å…·ä½“çš„ã«ã—ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"

# --- å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
if __name__ == "__main__":
    print("KeTCindy ChatBot ã¸ã‚ˆã†ã“ã")
    while True:
        user_input = input("è³ªå•ã‚’ã©ã†ãï¼ˆçµ‚äº†=exitï¼‰ï¼š")
        if user_input.lower() in ["exit", "quit"]:
            break
        try:
            answer = search_and_respond(user_input)
            print("ğŸ’¡ å›ç­”:", answer, "\n")
        except Exception as e:
            print("âš ï¸ ã‚¨ãƒ©ãƒ¼:", str(e))
